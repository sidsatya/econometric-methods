{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.api as smf # python linear regression package! \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the OLS Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will calculate the **ordinary least squares (OLS) estimator**, along with other important statistical measures using our very own model built from scratch in Python! \n",
    "\n",
    "Ordinary least squares is a classic and often-used linear least-squares method for estimating parameters in a linear regression model. For example, let's suppose there are $n$ observations, $(x_{i}, y_{i})$, where $x_{i}$ is a vector of $r$ regressors such that $x_{i} = [x_{i1}, x_{i2}, ..., x_{ir}]$. \n",
    "\n",
    "Then, we can write $y_{i}$ as a function of the regressors in order to obtain a linear model: \n",
    "\n",
    "$$ y = x^{T}\\beta + \\varepsilon$$ \n",
    "\n",
    "where $\\beta$ is a $r\\times1$ vector of parameters that we estimate via the ordinary least squares, $y$ and $\\varepsilon$ are $n\\times1$ vectors of the outcome variables (predicted) and the errors. $x$ is an $n\\times p$ matrix of the regressors. The estimate of the regression parameters, which is denoted as $\\hat{\\beta}$, is called the ordinary least squares estimator, and is given by the following equation:  \n",
    "\n",
    "$$\\hat{\\beta} = (x^{T}x)^{-1}x^{T}y$$\n",
    "\n",
    "Now, let's put this concept into practice by finding the OLS estimate for a sample regression! We will be using the same dataset as in the Ommitted Variable Bias notebook, with logwage as our outcome variable of interest, and state, age, education, and gender as regressors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our regression model is: \n",
    "\n",
    "$$ log(wage_{i}) = \\beta_{1}age_{i} + \\beta_{2}educ_{i} + \\beta_{3}female_{i} + \\varepsilon_{i}$$\n",
    "\n",
    "We can estimate the parameters $\\beta$ with the statsmodels API as below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>wagesal</th>\n",
       "      <th>imm</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>educ</th>\n",
       "      <th>wage</th>\n",
       "      <th>logwage</th>\n",
       "      <th>female</th>\n",
       "      <th>fedwkr</th>\n",
       "      <th>statewkr</th>\n",
       "      <th>localwkr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.109312</td>\n",
       "      <td>2.209297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>35600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17.115385</td>\n",
       "      <td>2.839978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>1.634756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>3.649659</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21902</th>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>60.096154</td>\n",
       "      <td>4.095946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21903</th>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>3.292984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21904</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>48208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>20.601709</td>\n",
       "      <td>3.025374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21905</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>75000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>36.057692</td>\n",
       "      <td>3.585120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21906</th>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>24.038462</td>\n",
       "      <td>3.179655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21907 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  age  wagesal  imm  hispanic  black  asian  educ       wage  \\\n",
       "0         11   44    18000    0         0      0      0    14   9.109312   \n",
       "1         11   39    18000    0         0      0      0    14  18.000000   \n",
       "2         11   39    35600    0         0      0      0    12  17.115385   \n",
       "3         11   39     8000    0         0      0      0    14   5.128205   \n",
       "4         11   39   100000    0         0      0      0    16  38.461538   \n",
       "...      ...  ...      ...  ...       ...    ...    ...   ...        ...   \n",
       "21902     95   36   125000    0         0      0      0    18  60.096154   \n",
       "21903     95   38    70000    0         0      0      1    18  26.923077   \n",
       "21904     95   43    48208    0         0      0      0    14  20.601709   \n",
       "21905     95   43    75000    0         0      0      0    18  36.057692   \n",
       "21906     95   44    50000    1         0      0      1    20  24.038462   \n",
       "\n",
       "        logwage  female  fedwkr  statewkr  localwkr  \n",
       "0      2.209297       1       1         0         0  \n",
       "1      2.890372       0       0         0         0  \n",
       "2      2.839978       0       0         0         1  \n",
       "3      1.634756       1       0         0         0  \n",
       "4      3.649659       0       1         0         0  \n",
       "...         ...     ...     ...       ...       ...  \n",
       "21902  4.095946       0       0         1         0  \n",
       "21903  3.292984       1       0         0         0  \n",
       "21904  3.025374       1       0         0         0  \n",
       "21905  3.585120       0       0         0         0  \n",
       "21906  3.179655       1       0         1         0  \n",
       "\n",
       "[21907 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "ovb_data = pd.read_csv('ovb.csv')\n",
    "ovb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y and x sets\n",
    "y = ovb_data['logwage'] \n",
    "\n",
    "# female is already a dummy variable that we can use. If there was also a male = 1 - female dummy variable, \n",
    "# then we would have to drop it from the regression due to perfect multicollinearity which would make the \n",
    "# inverse of the regressor matrix (design matrix) impossible to find. \n",
    "X = ovb_data[['age', 'educ', 'female']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates\n",
       "age           0.036325\n",
       "educ          0.119588\n",
       "female       -0.281464"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the estimated coefficients, using the OLS estimator equation above\n",
    "# NOTE: must convert Pandas Series to numpy arrays first\n",
    "\n",
    "def ols_estimator(X, y):\n",
    "    return np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "\n",
    "beta_hats = ols_estimator(np.array(X), np.array(y))\n",
    "\n",
    "regression_results = pd.DataFrame(index = ['age', 'educ', 'female'], \n",
    "                                      columns = ['Beta estimates'], \n",
    "                                      data=beta_hats)\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Variance and Standard Errors of Each Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are interested in studying not only what the estimated coefficients on our regressors are, but also how \"good\" of a fit these estimators provide. One way that we can do this is my looking at the variance of our OLS estimator and the standard errors.\n",
    "\n",
    "Assuming homoscedasticity, the variance of the OLS estimator is given by: \n",
    "\n",
    "$$Var(\\hat{\\beta}) = \\hat{\\sigma}^{2}_{\\varepsilon}(x^{T}x)^{-1}$$\n",
    "\n",
    "where $\\hat{\\sigma}^{2}_{\\varepsilon}$ is the variance of the error term. How do we find the variance of this error term? Well, in linear regression, the unbiased estimator of the error term is given by\n",
    "\n",
    "$$ \\hat{\\sigma}^{2}_{\\varepsilon} = \\frac{1}{n-p-1}\\sum_{i=1}^{n}{(y_{i} - \\hat{y}_{i})^{2}} = \\frac{1}{n-p-1}\\sum_{i=1}^{n}{\\hat{\\varepsilon}_{i}} $$\n",
    "\n",
    "where $n$ is the number of observations in the sample and $p$ is the number of regressors. It should also be noted that the summation term in the equation above is known as the **sum of squared residuals**.\n",
    "\n",
    "Thus, $Var(\\hat{\\beta})$ then becomes a square matrix of shape $r \\times r$, also known as the variance-covariance matrix. One property of this matrix is that it provides the covariance between pairs of elements in a random vector. Therefore, the matrix provided by $Var(\\hat{\\beta})$ contains the covariance between elements of $\\hat{\\beta}$. Furthermore, in order to find the **variance** of each individual coefficient, we must take each values on the diagonal of this matrix, since $Cov(\\hat{\\beta}_{i}, \\hat{\\beta}_{i}) = Var(\\hat{\\beta}_{i})$. To find the **standard error** of these values, we simply take the square root of the variance.\n",
    "\n",
    "Let's try to calculate these values below using our data and OLS coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.34945628e-07 -6.19448724e-07 -5.29988351e-07]\n",
      " [-6.19448724e-07  1.78907402e-06 -8.11555059e-07]\n",
      " [-5.29988351e-07 -8.11555059e-07  6.70192918e-05]]\n"
     ]
    }
   ],
   "source": [
    "def error_term_variance(n, p, X, beta_hats, y): \n",
    "    # calculate the predicted value of y\n",
    "    pred_y = np.dot(X, beta_hats) \n",
    "    # calculate the sum of squared residuals\n",
    "    SSR = np.sum((y - pred_y)**2)\n",
    "    # calculate the variance of the error term \n",
    "    return SSR/(n-p-1)\n",
    "\n",
    "def variance_covariance_matrix(sigma_hat, X): \n",
    "    return sigma_hat * np.linalg.inv(np.dot(X.T, X))\n",
    "\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "\n",
    "sigma_hat = error_term_variance(n, p, np.array(X), beta_hats, np.array(y))\n",
    "var_beta_hat = variance_covariance_matrix(sigma_hat, np.array(X))\n",
    "\n",
    "print(var_beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the displayed variance-covariance matrix -- taking the square root of values along the diagonal will provide us with the standard error for each term: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "      <th>Variances</th>\n",
       "      <th>Standard Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "      <td>2.349456e-07</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "      <td>1.789074e-06</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "      <td>6.701929e-05</td>\n",
       "      <td>0.008187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates     Variances  Standard Errors\n",
       "age           0.036325  2.349456e-07         0.000485\n",
       "educ          0.119588  1.789074e-06         0.001338\n",
       "female       -0.281464  6.701929e-05         0.008187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define function for these parts -- np.diagonal() is useful here! \n",
    "def coeff_var_from_var_matrix(matrix): \n",
    "    return matrix.diagonal()\n",
    "\n",
    "def coeff_se_from_var_matrix(matrix): \n",
    "    return np.sqrt(matrix.diagonal())\n",
    "\n",
    "variances = coeff_var_from_var_matrix(var_beta_hat)\n",
    "standard_errors = coeff_se_from_var_matrix(var_beta_hat)\n",
    "\n",
    "# add to the regression results!\n",
    "regression_results['Variances'] = variances\n",
    "regression_results['Standard Errors'] = standard_errors\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the t-statistic and Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the OLS estimates for the coefficients of interest, we may be additionally interested in whether or not these estimates are statistically significant or not. Two popular ways of measuring the significance of our estimates are through a t-test, or through the use of confidence intervals. \n",
    "\n",
    "**T-test:**\n",
    "\n",
    "For the purposes of a t-test in our regression, we want to find out whether or not our estimates support or reject the null hypothesis that the actual value is 0. More formally, we define two hypotheses about our estimated coeffiecients, a null hypothesis and an alternative hypothesis: \n",
    "\n",
    "$$ H_{0}: \\hat{\\beta} = 0 $$ \n",
    "$$ H_{1}: \\hat{\\beta} \\neq 0 $$ \n",
    "\n",
    "The null hypothesis essentially asserts that our estimated coefficient is not statistically significant from 0, so we cannot say with certainty that any affect is attributed to the specific regressor that coefficient is estimated for. The alternative hypothesis asserts that the estimated coeffcient is, in fact, statistically significant from 0, so we can report, with some level of confidence, the effect of a regressor on the dependent variable. It must be noted that the value of 0 chosen is not a hard and fast rule -- in reality, we can perform a t-test comparing our estimates against another values $a$, of our choosing. Most statistical packages use 0 as the value in a t-test, so we proceed with it in this example. \n",
    "\n",
    "In order to calculate the t-statistic for each estimate, $\\hat{\\beta}_{i}$, we use the following formula and compare their absolute values (magnitude) to critical values from a normal distribution to determine at what confidence we can say that our estimates are significant: \n",
    "\n",
    "$$ t = \\frac{\\hat{\\beta}_{i} - 0}{SE(\\hat{\\beta})} = \\frac{\\hat{\\beta}_{i}}{SE(\\hat{\\beta})}$$\n",
    "\n",
    "**Confidence Intervals:**\n",
    "\n",
    "In a similar way to calculating the t-statistic, the confidence interval instead defines an interval based on our estimates and their standard errors for a set of values for which a hypothesis to a certain level of confidence cannot be rejected. For example, for a hypothesis test at the 10% level, the interval will have a 90% probability. of containing the true value of $\\beta_{i}$.\n",
    "\n",
    "If this interval contains 0, then we cannot say that our estimates are statistically significant from 0. If the interval does not contain 0, we can say that our estimates are statistically signficant from 0 at that level of confidence. \n",
    "\n",
    "Below is the formula for calculating the confidence interval for each estimate, $\\hat{\\beta}_{i}$ at the 95% confidence interval: \n",
    "\n",
    "$$ CI = [\\hat{\\beta}_{i} - 1.96 \\times SE(\\hat{\\beta}_{i}), \\hat{\\beta}_{i} + 1.96 \\times SE(\\hat{\\beta}_{i})]$$\n",
    "\n",
    "The value of 1.96 corresponds to the z-score of a normal distribution for the 95% level of confidence. That is, 95% of the values in a normal distribution are contained between z-score values of +/- 1.96. This value will change for different confidence levels.\n",
    "\n",
    "Now, let's put these concepts to practice and calculate the t-statistics and confidence intervals for our estimates at the 95% level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "      <th>Variances</th>\n",
       "      <th>Standard Errors</th>\n",
       "      <th>T-statistics</th>\n",
       "      <th>90% Confidence Intervals</th>\n",
       "      <th>95% Confidence Intervals</th>\n",
       "      <th>99% Confidence Intervals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "      <td>2.349456e-07</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>74.9419</td>\n",
       "      <td>(0.0355, 0.0373)</td>\n",
       "      <td>(0.0354, 0.0373)</td>\n",
       "      <td>(0.0351, 0.0373)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "      <td>1.789074e-06</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>89.4073</td>\n",
       "      <td>(0.1174, 0.1222)</td>\n",
       "      <td>(0.117, 0.1222)</td>\n",
       "      <td>(0.1161, 0.1222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "      <td>6.701929e-05</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>-34.3813</td>\n",
       "      <td>(-0.2949, -0.2654)</td>\n",
       "      <td>(-0.2975, -0.2654)</td>\n",
       "      <td>(-0.3026, -0.2654)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates     Variances  Standard Errors  T-statistics  \\\n",
       "age           0.036325  2.349456e-07         0.000485       74.9419   \n",
       "educ          0.119588  1.789074e-06         0.001338       89.4073   \n",
       "female       -0.281464  6.701929e-05         0.008187      -34.3813   \n",
       "\n",
       "       90% Confidence Intervals 95% Confidence Intervals  \\\n",
       "age            (0.0355, 0.0373)         (0.0354, 0.0373)   \n",
       "educ           (0.1174, 0.1222)          (0.117, 0.1222)   \n",
       "female       (-0.2949, -0.2654)       (-0.2975, -0.2654)   \n",
       "\n",
       "       99% Confidence Intervals  \n",
       "age            (0.0351, 0.0373)  \n",
       "educ           (0.1161, 0.1222)  \n",
       "female       (-0.3026, -0.2654)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rounding the calculated values to avoid unnecessary messiness :)\n",
    "def t_stat(beta_hat, se): \n",
    "    return np.round(beta_hat/se, 4)\n",
    "\n",
    "def confidence_interval(beta_hat, se, z_score):\n",
    "    cis = [] \n",
    "    for i in range(len(beta_hat)): \n",
    "        left_side = np.round(beta_hat[i] - z_score*se[i], 4)\n",
    "        right_side = np.round(beta_hat[i] + 1.96*se[i], 4)\n",
    "        cis.append((left_side, right_side)) \n",
    "    return cis\n",
    "\n",
    "# using the beta hats and std. errors defined previously...\n",
    "t_statistics = t_stat(beta_hats, standard_errors)\n",
    "ci_90s = confidence_interval(beta_hats, standard_errors, 1.645) # 90% confidence\n",
    "ci_95s = confidence_interval(beta_hats, standard_errors, 1.96)  # 95% confidence\n",
    "ci_99s = confidence_interval(beta_hats, standard_errors, 2.576) # 99% confidence \n",
    "\n",
    "# add to the regression results!\n",
    "regression_results['T-statistics'] = t_statistics\n",
    "regression_results['90% Confidence Intervals'] = ci_90s\n",
    "regression_results['95% Confidence Intervals'] = ci_95s\n",
    "regression_results['99% Confidence Intervals'] = ci_99s\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (In Progress) Calculating R-squared and Adjusted R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Easier Way: Statsmodels API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! now that we have found the estimates for each coefficient, we can confirm the accuracy of our calculations using the statsmodels API. \n",
    "\n",
    "Using the statsmodels API, we can easily find the OLS regression estimates with a couple lines of code -- along with some extra statistics that are useful when conducting a regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                logwage   R-squared (uncentered):                   0.961\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.961\n",
      "Method:                 Least Squares   F-statistic:                          1.797e+05\n",
      "Date:                Thu, 04 Nov 2021   Prob (F-statistic):                        0.00\n",
      "Time:                        17:09:29   Log-Likelihood:                         -20071.\n",
      "No. Observations:               21907   AIC:                                  4.015e+04\n",
      "Df Residuals:                   21904   BIC:                                  4.017e+04\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age            0.0363      0.000     74.944      0.000       0.035       0.037\n",
      "educ           0.1196      0.001     89.409      0.000       0.117       0.122\n",
      "female        -0.2815      0.008    -34.382      0.000      -0.298      -0.265\n",
      "==============================================================================\n",
      "Omnibus:                     1068.934   Durbin-Watson:                   1.866\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3414.099\n",
      "Skew:                           0.174   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.902   Cond. No.                         84.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model1 = smf.OLS(y, X) \n",
    "res1 = model1.fit()\n",
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We can see that the estimated regression coefficients are shown in the table above, along with some relevant statistics such as $R^{2}$, standard error, the t-statistic, and the confidence interval for each coefficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (In Progress) Interpreting the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 1: A note on adding dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   R-squared:                       0.248\n",
      "Model:                            OLS   Adj. R-squared:                  0.248\n",
      "Method:                 Least Squares   F-statistic:                     2410.\n",
      "Date:                Mon, 08 Nov 2021   Prob (F-statistic):               0.00\n",
      "Time:                        18:51:47   Log-Likelihood:                -19882.\n",
      "No. Observations:               21907   AIC:                         3.977e+04\n",
      "Df Residuals:                   21903   BIC:                         3.980e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1694      0.060     19.530      0.000       1.052       1.287\n",
      "age            0.0101      0.001      7.126      0.000       0.007       0.013\n",
      "educ           0.1107      0.001     78.935      0.000       0.108       0.113\n",
      "female        -0.2874      0.008    -35.390      0.000      -0.303      -0.272\n",
      "==============================================================================\n",
      "Omnibus:                     1111.868   Durbin-Watson:                   1.856\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3584.968\n",
      "Skew:                           0.189   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.946   Cond. No.                         622.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X2 = smf.add_constant(X)\n",
    "model2 = smf.OLS(y, X2) \n",
    "res2 = model2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 2: OLS with just a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Mon, 08 Nov 2021   Prob (F-statistic):                nan\n",
      "Time:                        18:52:07   Log-Likelihood:                -23006.\n",
      "No. Observations:               21907   AIC:                         4.601e+04\n",
      "Df Residuals:                   21906   BIC:                         4.602e+04\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9816      0.005    638.095      0.000       2.972       2.991\n",
      "==============================================================================\n",
      "Omnibus:                      607.415   Durbin-Watson:                   1.719\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              958.546\n",
      "Skew:                           0.271   Prob(JB):                    7.15e-209\n",
      "Kurtosis:                       3.870   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X3 = np.ones(len(X))\n",
    "model3 = smf.OLS(y, X3) \n",
    "res3 = model3.fit()\n",
    "print(res3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9816"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(y),4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
