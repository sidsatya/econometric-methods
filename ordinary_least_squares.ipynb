{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.api as smf # python linear regression package! \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the OLS Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will calculate the **ordinary least squares (OLS) estimator**, along with other important statistical measures using our very own model built from scratch in Python! \n",
    "\n",
    "Ordinary least squares is a classic and often-used linear least-squares method for estimating parameters in a linear regression model. For example, let's suppose there are $n$ observations, $(x_{i}, y_{i})$, where $x_{i}$ is a vector of $r$ regressors such that $x_{i} = [x_{i1}, x_{i2}, ..., x_{ir}]$. \n",
    "\n",
    "Then, we can write $y_{i}$ as a function of the regressors in order to obtain a linear model: \n",
    "\n",
    "$$ y = x^{T}\\beta + \\varepsilon$$ \n",
    "\n",
    "where $\\beta$ is a $r\\times1$ vector of parameters that we estimate via the ordinary least squares, $y$ and $\\varepsilon$ are $n\\times1$ vectors of the outcome variables (predicted) and the errors. $x$ is an $n\\times p$ matrix of the regressors. The estimate of the regression parameters, which is denoted as $\\hat{\\beta}$, is called the ordinary least squares estimator, and is given by the following equation:  \n",
    "\n",
    "$$\\hat{\\beta} = (x^{T}x)^{-1}x^{T}y$$\n",
    "\n",
    "Now, let's put this concept into practice by finding the OLS estimate for a sample regression! We will be using the same dataset as in the Ommitted Variable Bias notebook, with logwage as our outcome variable of interest, and state, age, education, and gender as regressors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our regression model is: \n",
    "\n",
    "$$ log(wage_{i}) = \\beta_{1}age_{i} + \\beta_{2}educ_{i} + \\beta_{3}female_{i} + \\varepsilon_{i}$$\n",
    "\n",
    "We can estimate the parameters $\\beta$ with the statsmodels API as below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>wagesal</th>\n",
       "      <th>imm</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>asian</th>\n",
       "      <th>educ</th>\n",
       "      <th>wage</th>\n",
       "      <th>logwage</th>\n",
       "      <th>female</th>\n",
       "      <th>fedwkr</th>\n",
       "      <th>statewkr</th>\n",
       "      <th>localwkr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.109312</td>\n",
       "      <td>2.209297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>35600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17.115385</td>\n",
       "      <td>2.839978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>1.634756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>3.649659</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21902</th>\n",
       "      <td>95</td>\n",
       "      <td>36</td>\n",
       "      <td>125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>60.096154</td>\n",
       "      <td>4.095946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21903</th>\n",
       "      <td>95</td>\n",
       "      <td>38</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>3.292984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21904</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>48208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>20.601709</td>\n",
       "      <td>3.025374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21905</th>\n",
       "      <td>95</td>\n",
       "      <td>43</td>\n",
       "      <td>75000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>36.057692</td>\n",
       "      <td>3.585120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21906</th>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>24.038462</td>\n",
       "      <td>3.179655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21907 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  age  wagesal  imm  hispanic  black  asian  educ       wage  \\\n",
       "0         11   44    18000    0         0      0      0    14   9.109312   \n",
       "1         11   39    18000    0         0      0      0    14  18.000000   \n",
       "2         11   39    35600    0         0      0      0    12  17.115385   \n",
       "3         11   39     8000    0         0      0      0    14   5.128205   \n",
       "4         11   39   100000    0         0      0      0    16  38.461538   \n",
       "...      ...  ...      ...  ...       ...    ...    ...   ...        ...   \n",
       "21902     95   36   125000    0         0      0      0    18  60.096154   \n",
       "21903     95   38    70000    0         0      0      1    18  26.923077   \n",
       "21904     95   43    48208    0         0      0      0    14  20.601709   \n",
       "21905     95   43    75000    0         0      0      0    18  36.057692   \n",
       "21906     95   44    50000    1         0      0      1    20  24.038462   \n",
       "\n",
       "        logwage  female  fedwkr  statewkr  localwkr  \n",
       "0      2.209297       1       1         0         0  \n",
       "1      2.890372       0       0         0         0  \n",
       "2      2.839978       0       0         0         1  \n",
       "3      1.634756       1       0         0         0  \n",
       "4      3.649659       0       1         0         0  \n",
       "...         ...     ...     ...       ...       ...  \n",
       "21902  4.095946       0       0         1         0  \n",
       "21903  3.292984       1       0         0         0  \n",
       "21904  3.025374       1       0         0         0  \n",
       "21905  3.585120       0       0         0         0  \n",
       "21906  3.179655       1       0         1         0  \n",
       "\n",
       "[21907 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data\n",
    "ovb_data = pd.read_csv('ovb.csv')\n",
    "ovb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y and x sets\n",
    "y = ovb_data['logwage'] \n",
    "\n",
    "# female is already a dummy variable that we can use. If there was also a male = 1 - female dummy variable, \n",
    "# then we would have to drop it from the regression due to perfect multicollinearity which would make the \n",
    "# inverse of the regressor matrix (design matrix) impossible to find. \n",
    "X = ovb_data[['age', 'educ', 'female']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates\n",
       "age           0.036325\n",
       "educ          0.119588\n",
       "female       -0.281464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the estimated coefficients, using the OLS estimator equation above\n",
    "# NOTE: must convert Pandas Series to numpy arrays first\n",
    "\n",
    "def ols_estimator(X, y):\n",
    "    return np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "\n",
    "beta_hats = ols_estimator(np.array(X), np.array(y))\n",
    "\n",
    "regression_results = pd.DataFrame(index = ['age', 'educ', 'female'], \n",
    "                                      columns = ['Beta estimates'], \n",
    "                                      data=beta_hats)\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Variance and Standard Errors of Each Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are interested in studying not only what the estimated coefficients on our regressors are, but also how \"good\" of a fit these estimators provide. One way that we can do this is my looking at the variance of our OLS estimator and the standard errors.\n",
    "\n",
    "Assuming homoscedasticity, the variance of the OLS estimator is given by: \n",
    "\n",
    "$$Var(\\hat{\\beta}) = \\hat{\\sigma}^{2}_{\\varepsilon}(x^{T}x)^{-1}$$\n",
    "\n",
    "where $\\hat{\\sigma}^{2}_{\\varepsilon}$ is the variance of the error term. How do we find the variance of this error term? Well, in linear regression, the unbiased estimator of variance of the error term is given by\n",
    "\n",
    "$$ \\hat{\\sigma}^{2}_{\\varepsilon} = \\frac{1}{n-p-1}\\sum_{i=1}^{n}{(y_{i} - \\hat{y}_{i})^{2}} = \\frac{1}{n-p-1}\\sum_{i=1}^{n}{\\hat{\\varepsilon}_{i}} $$\n",
    "\n",
    "where $n$ is the number of observations in the sample and $p$ is the number of regressors (parameters). It should also be noted that the summation term in the equation above is known as the **sum of squared residuals**.\n",
    "\n",
    "Thus, $Var(\\hat{\\beta})$ then becomes a square matrix of shape $r \\times r$, also known as the variance-covariance matrix. One property of this matrix is that it provides the covariance between pairs of elements in a random vector. Therefore, the matrix provided by $Var(\\hat{\\beta})$ contains the covariance between elements of $\\hat{\\beta}$. Furthermore, in order to find the **variance** of each individual coefficient, we must take each values on the diagonal of this matrix, since $Cov(\\hat{\\beta}_{i}, \\hat{\\beta}_{i}) = Var(\\hat{\\beta}_{i})$. To find the **standard error** of these values, we simply take the square root of the variance.\n",
    "\n",
    "Let's try to calculate these values below using our data and OLS coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.34945628e-07 -6.19448724e-07 -5.29988351e-07]\n",
      " [-6.19448724e-07  1.78907402e-06 -8.11555059e-07]\n",
      " [-5.29988351e-07 -8.11555059e-07  6.70192918e-05]]\n"
     ]
    }
   ],
   "source": [
    "def error_term_variance(n, p, X, beta_hats, y): \n",
    "    # calculate the predicted value of y\n",
    "    pred_y = np.dot(X, beta_hats) \n",
    "    # calculate the sum of squared residuals\n",
    "    SSR = np.sum((y - pred_y)**2)\n",
    "    # calculate the variance of the error term \n",
    "    return SSR/(n-p-1)\n",
    "\n",
    "def variance_covariance_matrix(sigma_hat, X): \n",
    "    return sigma_hat * np.linalg.inv(np.dot(X.T, X))\n",
    "\n",
    "n = X.shape[0]\n",
    "p = X.shape[1]\n",
    "\n",
    "sigma_hat = error_term_variance(n, p, np.array(X), beta_hats, np.array(y))\n",
    "var_beta_hat = variance_covariance_matrix(sigma_hat, np.array(X))\n",
    "\n",
    "print(var_beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the displayed variance-covariance matrix -- taking the square root of values along the diagonal will provide us with the standard error for each term: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "      <th>Variances</th>\n",
       "      <th>Standard Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "      <td>2.349456e-07</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "      <td>1.789074e-06</td>\n",
       "      <td>0.001338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "      <td>6.701929e-05</td>\n",
       "      <td>0.008187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates     Variances  Standard Errors\n",
       "age           0.036325  2.349456e-07         0.000485\n",
       "educ          0.119588  1.789074e-06         0.001338\n",
       "female       -0.281464  6.701929e-05         0.008187"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define function for these parts -- np.diagonal() is useful here! \n",
    "def coeff_var_from_var_matrix(matrix): \n",
    "    return matrix.diagonal()\n",
    "\n",
    "def coeff_se_from_var_matrix(matrix): \n",
    "    return np.sqrt(matrix.diagonal())\n",
    "\n",
    "variances = coeff_var_from_var_matrix(var_beta_hat)\n",
    "standard_errors = coeff_se_from_var_matrix(var_beta_hat)\n",
    "\n",
    "# add to the regression results!\n",
    "regression_results['Variances'] = variances\n",
    "regression_results['Standard Errors'] = standard_errors\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the t-statistic and Confidence Interval for each Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the OLS estimates for the coefficients of interest, we may be additionally interested in whether or not these estimates are statistically significant or not. Two popular ways of measuring the significance of our estimates are through a t-test, or through the use of confidence intervals. \n",
    "\n",
    "**T-test:**\n",
    "\n",
    "For the purposes of a t-test in our regression, we want to find out whether or not our estimates support or reject the null hypothesis that the actual value is 0. More formally, we define two hypotheses about our estimated coeffiecients, a null hypothesis and an alternative hypothesis: \n",
    "\n",
    "$$ H_{0}: \\hat{\\beta}_{i} = 0 $$ \n",
    "$$ H_{1}: \\hat{\\beta}_{i} \\neq 0 $$ \n",
    "\n",
    "The null hypothesis essentially asserts that our estimated coefficient is not statistically significant from 0, so we cannot say with certainty that any affect is attributed to the specific regressor that coefficient is estimated for. The alternative hypothesis asserts that the estimated coeffcient is, in fact, statistically significant from 0, so we can report, with some level of confidence, the effect of a regressor on the dependent variable. It must be noted that the value of 0 chosen is not a hard and fast rule -- in reality, we can perform a t-test comparing our estimates against another values $a$, of our choosing. Most statistical packages use 0 as the value in a t-test, so we proceed with it in this example. \n",
    "\n",
    "In order to calculate the t-statistic for each estimate, $\\hat{\\beta}_{i}$, we use the following formula and compare their absolute values (magnitude) to critical values from a normal distribution to determine at what confidence we can say that our estimates are significant: \n",
    "\n",
    "$$ t = \\frac{\\hat{\\beta}_{i} - 0}{SE(\\hat{\\beta})} = \\frac{\\hat{\\beta}_{i}}{SE(\\hat{\\beta})}$$\n",
    "\n",
    "**Confidence Intervals:**\n",
    "\n",
    "In a similar way to calculating the t-statistic, the confidence interval instead defines an interval based on our estimates and their standard errors for a set of values for which a hypothesis to a certain level of confidence cannot be rejected. For example, for a hypothesis test at the 10% level, the interval will have a 90% probability. of containing the true value of $\\beta_{i}$.\n",
    "\n",
    "If this interval contains 0, then we cannot say that our estimates are statistically significant from 0. If the interval does not contain 0, we can say that our estimates are statistically signficant from 0 at that level of confidence. \n",
    "\n",
    "Below is the formula for calculating the confidence interval for each estimate, $\\hat{\\beta}_{i}$ at the 95% confidence interval: \n",
    "\n",
    "$$ CI = [\\hat{\\beta}_{i} - 1.96 \\times SE(\\hat{\\beta}_{i}), \\hat{\\beta}_{i} + 1.96 \\times SE(\\hat{\\beta}_{i})]$$\n",
    "\n",
    "The value of 1.96 corresponds to the z-score of a normal distribution for the 95% level of confidence. That is, 95% of the values in a normal distribution are contained between z-score values of +/- 1.96. This value will change for different confidence levels.\n",
    "\n",
    "Now, let's put these concepts to practice and calculate the t-statistics and confidence intervals for our estimates at the 95% level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "      <th>Variances</th>\n",
       "      <th>Standard Errors</th>\n",
       "      <th>T-statistics</th>\n",
       "      <th>90% Confidence Intervals</th>\n",
       "      <th>95% Confidence Intervals</th>\n",
       "      <th>99% Confidence Intervals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "      <td>2.349456e-07</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>74.9419</td>\n",
       "      <td>(0.0355, 0.0373)</td>\n",
       "      <td>(0.0354, 0.0373)</td>\n",
       "      <td>(0.0351, 0.0373)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "      <td>1.789074e-06</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>89.4073</td>\n",
       "      <td>(0.1174, 0.1222)</td>\n",
       "      <td>(0.117, 0.1222)</td>\n",
       "      <td>(0.1161, 0.1222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "      <td>6.701929e-05</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>-34.3813</td>\n",
       "      <td>(-0.2949, -0.2654)</td>\n",
       "      <td>(-0.2975, -0.2654)</td>\n",
       "      <td>(-0.3026, -0.2654)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates     Variances  Standard Errors  T-statistics  \\\n",
       "age           0.036325  2.349456e-07         0.000485       74.9419   \n",
       "educ          0.119588  1.789074e-06         0.001338       89.4073   \n",
       "female       -0.281464  6.701929e-05         0.008187      -34.3813   \n",
       "\n",
       "       90% Confidence Intervals 95% Confidence Intervals  \\\n",
       "age            (0.0355, 0.0373)         (0.0354, 0.0373)   \n",
       "educ           (0.1174, 0.1222)          (0.117, 0.1222)   \n",
       "female       (-0.2949, -0.2654)       (-0.2975, -0.2654)   \n",
       "\n",
       "       99% Confidence Intervals  \n",
       "age            (0.0351, 0.0373)  \n",
       "educ           (0.1161, 0.1222)  \n",
       "female       (-0.3026, -0.2654)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rounding the calculated values to avoid unnecessary messiness :)\n",
    "def t_stat(beta_hat, se): \n",
    "    return np.round(beta_hat/se, 4)\n",
    "\n",
    "def confidence_interval(beta_hat, se, z_score):\n",
    "    cis = [] \n",
    "    for i in range(len(beta_hat)): \n",
    "        left_side = np.round(beta_hat[i] - z_score*se[i], 4)\n",
    "        right_side = np.round(beta_hat[i] + 1.96*se[i], 4)\n",
    "        cis.append((left_side, right_side)) \n",
    "    return cis\n",
    "\n",
    "# using the beta hats and std. errors defined previously...\n",
    "t_statistics = t_stat(beta_hats, standard_errors)\n",
    "ci_90s = confidence_interval(beta_hats, standard_errors, 1.645) # 90% confidence\n",
    "ci_95s = confidence_interval(beta_hats, standard_errors, 1.96)  # 95% confidence\n",
    "ci_99s = confidence_interval(beta_hats, standard_errors, 2.576) # 99% confidence \n",
    "\n",
    "# add to the regression results!\n",
    "regression_results['T-statistics'] = t_statistics\n",
    "regression_results['90% Confidence Intervals'] = ci_90s\n",
    "regression_results['95% Confidence Intervals'] = ci_95s\n",
    "regression_results['99% Confidence Intervals'] = ci_99s\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $R^{2}$ and Adjusted $R^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$R^{2}$:**\n",
    "\n",
    "Another important statistic that is helpful to track when using OLS (and other types of regressions) is the coefficient of determination, or $R^{2}$. Essentially, the statistic calculates the proportion of the variation in the dependent variable that is explained by the independent variable(s). For example, if the $R^{2} = 0.49$ then we would say that 49% of the variation in the dependent variable in the data we are observing is explained by the independent regressors that we have included.\n",
    "\n",
    "To calculate $R^{2}$, we must first find the values for the **sum of squared residuals (SSR)** and the **total sum of squares (TSS)**: \n",
    "\n",
    "$$ SSR = \\sum_{i=1}^{n}{(y_{i} - \\hat{y}_{i})^{2}}$$\n",
    "\n",
    "$$ TSS \\text{ (uncentered)} = \\sum_{i=1}^{n}{(y_{i})^{2}} $$\n",
    "\n",
    "$$ TSS \\text{ (centered)} = \\sum_{i=1}^{n}{(y_{i} - \\bar{y})^{2}} $$\n",
    "\n",
    "One way to think about the SSR is as the amount of unexplained variation in the dependent variable. The TSS can be viewed as total variation in the dependent variable (you can see that is formulation is very similar to the variance formula) and is thus proportional to the variance of the data. The reason for there being two separate types of TSS (centered vs. uncentered), is due to model specification. If we include a constant in our model specification, then we would use the centered TSS. If not, we would use the uncentered TSS since $E[y] = 0$ and thus $E[(y - E[y])^{2}] = E[y^{2}]$. \n",
    "\n",
    "To calculate $R^{2}$, we find, \n",
    "$$R^{2} = 1 - \\frac{SSR}{TSS}$$\n",
    "\n",
    "The lower bound is 0 for $R^{2}$, when SSR = TSS -- this means that the model is no better than a constant. The upper bound is 1 when SSR = 0, which means that the model perfectly explains all the variation in the data.\n",
    "\n",
    "**Adjusted $R^{2}$:**\n",
    "\n",
    "You might have noticed that the classic $R^{2}$ statistic suffers from one problem when we measure the \"goodness\" of fit for our model: it can only get better as we add more and more regressors as the statistic does not penalize adding more regressors even if they do not add much! This can be problematic, since we know that it often not beneficial to add as many regressors as we can (multicollinearity comes to mind). \n",
    "\n",
    "One way to correct for this is to calculate Adjusted $R^{2}$, which is a \"stricter\" statistic as it penalizes the model for extra regressors by replacing the SSR and TSS terms with degrees of freedom corrected terms: \n",
    "\n",
    "$$ \\text{Adjusted } R^{2} = 1 - \\frac{\\frac{1}{n-p}SSR}{\\frac{1}{n-1}TSS}$$\n",
    "\n",
    "The idea behind these \"df corrected\" terms is that if we had $p$ regressors and a sample size of $n = p$, then you could perfectly predict each of the dependent variables. Thus, as we add more regressors, the numerator grows larger and the Adjusted $R^{2}$ will fall as a result.\n",
    "\n",
    "Let's put this into practice and calculate these statistics for our OLS model!\n",
    "\n",
    "**Note:** both $R^{2}$ and Adjusted $R^{2}$ are calculate for the whole model, not a single parameter estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta estimates</th>\n",
       "      <th>Variances</th>\n",
       "      <th>Standard Errors</th>\n",
       "      <th>T-statistics</th>\n",
       "      <th>90% Confidence Intervals</th>\n",
       "      <th>95% Confidence Intervals</th>\n",
       "      <th>99% Confidence Intervals</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>Adjusted R-squared</th>\n",
       "      <th>R-squared (uncentered)</th>\n",
       "      <th>Adjusted R-squared (uncentered)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.036325</td>\n",
       "      <td>2.349456e-07</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>74.9419</td>\n",
       "      <td>(0.0355, 0.0373)</td>\n",
       "      <td>(0.0354, 0.0373)</td>\n",
       "      <td>(0.0351, 0.0373)</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.960943</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.960943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.119588</td>\n",
       "      <td>1.789074e-06</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>89.4073</td>\n",
       "      <td>(0.1174, 0.1222)</td>\n",
       "      <td>(0.117, 0.1222)</td>\n",
       "      <td>(0.1161, 0.1222)</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.960943</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.960943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>-0.281464</td>\n",
       "      <td>6.701929e-05</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>-34.3813</td>\n",
       "      <td>(-0.2949, -0.2654)</td>\n",
       "      <td>(-0.2975, -0.2654)</td>\n",
       "      <td>(-0.3026, -0.2654)</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.960943</td>\n",
       "      <td>0.960947</td>\n",
       "      <td>0.960943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Beta estimates     Variances  Standard Errors  T-statistics  \\\n",
       "age           0.036325  2.349456e-07         0.000485       74.9419   \n",
       "educ          0.119588  1.789074e-06         0.001338       89.4073   \n",
       "female       -0.281464  6.701929e-05         0.008187      -34.3813   \n",
       "\n",
       "       90% Confidence Intervals 95% Confidence Intervals  \\\n",
       "age            (0.0355, 0.0373)         (0.0354, 0.0373)   \n",
       "educ           (0.1174, 0.1222)          (0.117, 0.1222)   \n",
       "female       (-0.2949, -0.2654)       (-0.2975, -0.2654)   \n",
       "\n",
       "       99% Confidence Intervals  R-squared  Adjusted R-squared  \\\n",
       "age            (0.0351, 0.0373)   0.960947            0.960943   \n",
       "educ           (0.1161, 0.1222)   0.960947            0.960943   \n",
       "female       (-0.3026, -0.2654)   0.960947            0.960943   \n",
       "\n",
       "        R-squared (uncentered)  Adjusted R-squared (uncentered)  \n",
       "age                   0.960947                         0.960943  \n",
       "educ                  0.960947                         0.960943  \n",
       "female                0.960947                         0.960943  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_of_squared_residuals(y, y_pred): \n",
    "    return np.sum((y - y_pred)**2)\n",
    "\n",
    "def total_sum_of_squares_uncentered(y): \n",
    "    return np.sum((y)**2)\n",
    "\n",
    "def total_sum_of_squares_centered(y): \n",
    "    return np.sum((y-np.mean(y))**2)\n",
    "\n",
    "def r_squared(ssr, tss): \n",
    "    return 1 - ssr/tss\n",
    "\n",
    "def adj_r_squared(ssr, tss, n, p):\n",
    "    return 1 - (ssr/(n-p))/(tss/(n-1))\n",
    "\n",
    "# calculate preliminary statistics\n",
    "\n",
    "n = np.shape(X)[0]             # number of obs \n",
    "p = np.shape(X)[1]             # number of parameters\n",
    "y_pred = np.dot(X, beta_hats)  # predicted y's \n",
    "\n",
    "ssr = sum_of_squared_residuals(y, y_pred)\n",
    "tss = total_sum_of_squares_uncentered(y) \n",
    "\n",
    "# calculate r_squared \n",
    "r_2 = r_squared(ssr, tss) \n",
    "adj_r_2 = adj_r_squared(ssr, tss, n, p)\n",
    "\n",
    "# add these to our regression results! \n",
    "regression_results['R-squared (uncentered)'] = np.ones(3)*r_2\n",
    "regression_results['Adjusted R-squared (uncentered)'] = np.ones(3)*adj_r_2\n",
    "\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it! We have calculated a large number of helpful statistics for our very own OLS regression from scratch! Now that we've completed all the fun parts, lets see how we can very easily compute all of these statistics (and more) using the Statsmodels API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Easier Way: Statsmodels API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the estimates for each coefficient, we can confirm the accuracy of our calculations using the statsmodels API. \n",
    "\n",
    "Using the statsmodels API, we can easily find the OLS regression estimates with a couple lines of code -- along with some extra statistics that are useful when conducting a regression analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                logwage   R-squared (uncentered):                   0.961\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.961\n",
      "Method:                 Least Squares   F-statistic:                          1.797e+05\n",
      "Date:                Fri, 12 Nov 2021   Prob (F-statistic):                        0.00\n",
      "Time:                        18:01:50   Log-Likelihood:                         -20071.\n",
      "No. Observations:               21907   AIC:                                  4.015e+04\n",
      "Df Residuals:                   21904   BIC:                                  4.017e+04\n",
      "Df Model:                           3                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age            0.0363      0.000     74.944      0.000       0.035       0.037\n",
      "educ           0.1196      0.001     89.409      0.000       0.117       0.122\n",
      "female        -0.2815      0.008    -34.382      0.000      -0.298      -0.265\n",
      "==============================================================================\n",
      "Omnibus:                     1068.934   Durbin-Watson:                   1.866\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3414.099\n",
      "Skew:                           0.174   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.902   Cond. No.                         84.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model1 = smf.OLS(y, X) \n",
    "res1 = model1.fit()\n",
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We can see that the estimated regression coefficients are shown in the table above, along with some relevant statistics such as $R^{2}$, standard error, the t-statistic, and the confidence interval for each coefficient. Furthermore, comparing these results to our calculated regression coefficients above, we can see that the numbers are practically the same. \n",
    "\n",
    "The hope so far is that you are now comfortable with some of the math and intuition behind the common regression packages that can be used in Python. Let's package all of this together by now moving forward with actually **interpreting** the results of our regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (In Progress) Interpreting the regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 1: How to add a constant term to the Statsmodels API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of adding a constant when running a statsmodels OLS regression. We can see that the values for the $R^{2}$ and Adjusted $R^{2}$ are now equal to their \"centered\" versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   R-squared:                       0.248\n",
      "Model:                            OLS   Adj. R-squared:                  0.248\n",
      "Method:                 Least Squares   F-statistic:                     2410.\n",
      "Date:                Fri, 12 Nov 2021   Prob (F-statistic):               0.00\n",
      "Time:                        18:36:10   Log-Likelihood:                -19882.\n",
      "No. Observations:               21907   AIC:                         3.977e+04\n",
      "Df Residuals:                   21903   BIC:                         3.980e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1694      0.060     19.530      0.000       1.052       1.287\n",
      "age            0.0101      0.001      7.126      0.000       0.007       0.013\n",
      "educ           0.1107      0.001     78.935      0.000       0.108       0.113\n",
      "female        -0.2874      0.008    -35.390      0.000      -0.303      -0.272\n",
      "==============================================================================\n",
      "Omnibus:                     1111.868   Durbin-Watson:                   1.856\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3584.968\n",
      "Skew:                           0.189   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.946   Cond. No.                         622.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X2 = smf.add_constant(X)\n",
    "model2 = smf.OLS(y, X2) \n",
    "res2 = model2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 2: OLS with just a constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run OLS regressions with just a constant as the independent regressor, our estimated coefficient will end up just being the mean of the the observations of the dependent variable that we have. Below we demonstrate this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                logwage   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Fri, 12 Nov 2021   Prob (F-statistic):                nan\n",
      "Time:                        18:32:25   Log-Likelihood:                -23006.\n",
      "No. Observations:               21907   AIC:                         4.601e+04\n",
      "Df Residuals:                   21906   BIC:                         4.602e+04\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9816      0.005    638.095      0.000       2.972       2.991\n",
      "==============================================================================\n",
      "Omnibus:                      607.415   Durbin-Watson:                   1.719\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              958.546\n",
      "Skew:                           0.271   Prob(JB):                    7.15e-209\n",
      "Kurtosis:                       3.870   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X3 = np.ones(len(X))\n",
    "model3 = smf.OLS(y, X3) \n",
    "res3 = model3.fit()\n",
    "print(res3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated OLS coefficient with just a constant is  2.9816119732445805 . The mean of y is:  2.981611973244579 . Thus, we can see that the two are the same!\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated OLS coefficient with just a constant is \", res3.params[0], \n",
    "      \". The mean of y is: \", np.mean(y), \". Thus, we can see that the two are the same!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
